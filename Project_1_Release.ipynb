{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_1_Release.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OceanZhang1988/CS4641/blob/main/Project_1_Release.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHcRhmJvuShp"
      },
      "source": [
        "# Licensing Information:  You are free to use or extend this project for\n",
        "# educational purposes provided that (1) you do not distribute or publish\n",
        "# solutions, (2) you retain this notice, and (3) you provide clear\n",
        "# attribution to The Georgia Institute of Technology, including a link to https://aritter.github.io/CS-7650/\n",
        " \n",
        "# Attribution Information: This assignment was developed at The Georgia Institute of Technology\n",
        "# by Alan Ritter (alan.ritter@cc.gatech.edu)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEU47Vc4yhlS"
      },
      "source": [
        "#Project \\#1: Decision Trees\n",
        "\n",
        "In this assignment you will implement a decision tree learning algorithm that uses information gain as the splitting criterea.\n",
        "\n",
        "In this notebook, we provide you with some starter code to read in the data and evaluate the performance of your implementation. After completing the instructions below, please follow the instructions at the end to submit your notebook and other files to Gradescope.\n",
        "\n",
        "Make sure to make a copy of this notebook, so your changes are saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prrcH7X6SIY-"
      },
      "source": [
        "#Download the dataset\n",
        "\n",
        "First, let's download the experimental data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLdBGiwmVy5n",
        "outputId": "5d396652-0966-486c-ead1-3c2910541fcc"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/aritter/CS-4641/main/data/train.data\n",
        "!wget https://raw.githubusercontent.com/aritter/CS-4641/main/data/dev.data\n",
        "!wget https://raw.githubusercontent.com/aritter/CS-4641/main/data/test.data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-05 07:06:49--  https://raw.githubusercontent.com/aritter/CS-4641/main/data/train.data\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 230000 (225K) [text/plain]\n",
            "Saving to: ‘train.data’\n",
            "\n",
            "\rtrain.data            0%[                    ]       0  --.-KB/s               \rtrain.data          100%[===================>] 224.61K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-09-05 07:06:49 (13.5 MB/s) - ‘train.data’ saved [230000/230000]\n",
            "\n",
            "--2021-09-05 07:06:49--  https://raw.githubusercontent.com/aritter/CS-4641/main/data/dev.data\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46000 (45K) [text/plain]\n",
            "Saving to: ‘dev.data’\n",
            "\n",
            "dev.data            100%[===================>]  44.92K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-09-05 07:06:49 (24.3 MB/s) - ‘dev.data’ saved [46000/46000]\n",
            "\n",
            "--2021-09-05 07:06:49--  https://raw.githubusercontent.com/aritter/CS-4641/main/data/test.data\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 97704 (95K) [text/plain]\n",
            "Saving to: ‘test.data’\n",
            "\n",
            "test.data           100%[===================>]  95.41K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-09-05 07:06:49 (9.58 MB/s) - ‘test.data’ saved [97704/97704]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_T0TdaAWAav"
      },
      "source": [
        "Here is a look at what the data looks like.  Also note that in Colab you can run Linux shell commands by prepending them with a `!` like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh5ZlWkpV9Qr",
        "outputId": "b3c671d9-3fdd-4b04-dd08-5e902e153dd6"
      },
      "source": [
        "!head train.data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e,x,s,g,f,n,f,w,b,p,t,e,f,s,w,w,p,w,o,e,k,s,g\n",
            "p,x,f,y,f,f,f,c,b,h,e,b,k,k,n,n,p,w,o,l,h,v,p\n",
            "p,f,s,e,f,y,f,c,n,b,t,?,s,s,w,w,p,w,o,e,w,v,l\n",
            "e,f,f,w,f,n,f,w,b,p,t,e,f,f,w,w,p,w,o,e,k,s,g\n",
            "p,f,y,y,f,f,f,c,b,g,e,b,k,k,p,n,p,w,o,l,h,v,g\n",
            "e,x,s,g,f,n,f,w,b,p,t,e,f,f,w,w,p,w,o,e,n,a,g\n",
            "p,b,s,p,t,n,f,c,b,r,e,b,s,s,w,w,p,w,t,p,r,v,g\n",
            "e,x,y,y,t,l,f,c,b,k,e,c,s,s,w,w,p,w,o,p,n,n,m\n",
            "e,x,y,r,f,n,f,c,n,w,e,?,s,f,w,w,p,w,o,f,h,y,d\n",
            "e,f,f,e,t,n,f,c,b,p,t,b,s,s,g,g,p,w,o,p,k,v,d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu5P3NHRWHlc"
      },
      "source": [
        "Each row describes a mushroom. The first column indicates whether it is edible 'e' or poisonous 'p' (this is the label we will try to predict).  The remaining columns are various discrete features which may be helpful in determining whether the mushroom is poisonous.  In case you were curious, the following is a description of the meaning of each feature.  **Disclaimer: please do not use your model's learned decision tree to determine whether to eat a mushroom!**\n",
        "\n",
        "1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=*s*\n",
        "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
        "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\n",
        "4. bruises?: bruises=t,no=f\n",
        "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n",
        "6. gill-attachment: attached=a,descending=d,free=f,notched=n\n",
        "7. gill-spacing: close=c,crowded=w,distant=d\n",
        "8. gill-size: broad=b,narrow=n\n",
        "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y\n",
        "10. stalk-shape: enlarging=e,tapering=t\n",
        "11. stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\n",
        "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
        "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
        "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
        "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
        "16. veil-type: partial=p,universal=u\n",
        "17. veil-color: brown=n,orange=o,white=w,yellow=y\n",
        "18. ring-number: none=n,one=o,two=t\n",
        "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\n",
        "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\n",
        "21. population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\n",
        "22. habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_1ato4PWUhZ"
      },
      "source": [
        "#Dataloader\n",
        "\n",
        "The code below reads in the data and represents each mushroom as a list of `FeatureVal` named tuples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e7PeBFyWIJ1"
      },
      "source": [
        "from collections import namedtuple\n",
        "import sys\n",
        "import math\n",
        "\n",
        "FeatureVal = namedtuple(\"FeatureVal\", \"feature, value\")        \n",
        "\n",
        "class MushroomData:\n",
        "    def __init__(self, fileName):\n",
        "        self.data = []\n",
        "        self.features = set()\n",
        "        for line in open(fileName):\n",
        "            line = line.strip()            \n",
        "            attributes = line.split(',')\n",
        "            for i in range(1,len(attributes)):\n",
        "                self.features.add(FeatureVal(i, attributes[i]))\n",
        "            self.data.append(attributes)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO1ubSubW-ue"
      },
      "source": [
        "Let's see what that looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv9vWAryW4P1",
        "outputId": "b1ffefb4-e602-450b-8dc8-4d89410f71f3"
      },
      "source": [
        "train = MushroomData('train.data')\n",
        "dev = MushroomData('dev.data')\n",
        "test = MushroomData('test.data')\n",
        "\n",
        "print(\"list of possible feature values indexed by position:\", sorted(train.features))\n",
        "print(\"first training example:\", train.data[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list of possible feature values indexed by position: [FeatureVal(feature=1, value='b'), FeatureVal(feature=1, value='c'), FeatureVal(feature=1, value='f'), FeatureVal(feature=1, value='k'), FeatureVal(feature=1, value='s'), FeatureVal(feature=1, value='x'), FeatureVal(feature=2, value='f'), FeatureVal(feature=2, value='g'), FeatureVal(feature=2, value='s'), FeatureVal(feature=2, value='y'), FeatureVal(feature=3, value='b'), FeatureVal(feature=3, value='c'), FeatureVal(feature=3, value='e'), FeatureVal(feature=3, value='g'), FeatureVal(feature=3, value='n'), FeatureVal(feature=3, value='p'), FeatureVal(feature=3, value='r'), FeatureVal(feature=3, value='u'), FeatureVal(feature=3, value='w'), FeatureVal(feature=3, value='y'), FeatureVal(feature=4, value='f'), FeatureVal(feature=4, value='t'), FeatureVal(feature=5, value='a'), FeatureVal(feature=5, value='c'), FeatureVal(feature=5, value='f'), FeatureVal(feature=5, value='l'), FeatureVal(feature=5, value='m'), FeatureVal(feature=5, value='n'), FeatureVal(feature=5, value='p'), FeatureVal(feature=5, value='s'), FeatureVal(feature=5, value='y'), FeatureVal(feature=6, value='a'), FeatureVal(feature=6, value='f'), FeatureVal(feature=7, value='c'), FeatureVal(feature=7, value='w'), FeatureVal(feature=8, value='b'), FeatureVal(feature=8, value='n'), FeatureVal(feature=9, value='b'), FeatureVal(feature=9, value='e'), FeatureVal(feature=9, value='g'), FeatureVal(feature=9, value='h'), FeatureVal(feature=9, value='k'), FeatureVal(feature=9, value='n'), FeatureVal(feature=9, value='o'), FeatureVal(feature=9, value='p'), FeatureVal(feature=9, value='r'), FeatureVal(feature=9, value='u'), FeatureVal(feature=9, value='w'), FeatureVal(feature=9, value='y'), FeatureVal(feature=10, value='e'), FeatureVal(feature=10, value='t'), FeatureVal(feature=11, value='?'), FeatureVal(feature=11, value='b'), FeatureVal(feature=11, value='c'), FeatureVal(feature=11, value='e'), FeatureVal(feature=11, value='r'), FeatureVal(feature=12, value='f'), FeatureVal(feature=12, value='k'), FeatureVal(feature=12, value='s'), FeatureVal(feature=12, value='y'), FeatureVal(feature=13, value='f'), FeatureVal(feature=13, value='k'), FeatureVal(feature=13, value='s'), FeatureVal(feature=13, value='y'), FeatureVal(feature=14, value='b'), FeatureVal(feature=14, value='c'), FeatureVal(feature=14, value='e'), FeatureVal(feature=14, value='g'), FeatureVal(feature=14, value='n'), FeatureVal(feature=14, value='o'), FeatureVal(feature=14, value='p'), FeatureVal(feature=14, value='w'), FeatureVal(feature=14, value='y'), FeatureVal(feature=15, value='b'), FeatureVal(feature=15, value='c'), FeatureVal(feature=15, value='e'), FeatureVal(feature=15, value='g'), FeatureVal(feature=15, value='n'), FeatureVal(feature=15, value='o'), FeatureVal(feature=15, value='p'), FeatureVal(feature=15, value='w'), FeatureVal(feature=15, value='y'), FeatureVal(feature=16, value='p'), FeatureVal(feature=17, value='n'), FeatureVal(feature=17, value='o'), FeatureVal(feature=17, value='w'), FeatureVal(feature=17, value='y'), FeatureVal(feature=18, value='n'), FeatureVal(feature=18, value='o'), FeatureVal(feature=18, value='t'), FeatureVal(feature=19, value='e'), FeatureVal(feature=19, value='f'), FeatureVal(feature=19, value='l'), FeatureVal(feature=19, value='n'), FeatureVal(feature=19, value='p'), FeatureVal(feature=20, value='b'), FeatureVal(feature=20, value='h'), FeatureVal(feature=20, value='k'), FeatureVal(feature=20, value='n'), FeatureVal(feature=20, value='o'), FeatureVal(feature=20, value='r'), FeatureVal(feature=20, value='u'), FeatureVal(feature=20, value='w'), FeatureVal(feature=20, value='y'), FeatureVal(feature=21, value='a'), FeatureVal(feature=21, value='c'), FeatureVal(feature=21, value='n'), FeatureVal(feature=21, value='s'), FeatureVal(feature=21, value='v'), FeatureVal(feature=21, value='y'), FeatureVal(feature=22, value='d'), FeatureVal(feature=22, value='g'), FeatureVal(feature=22, value='l'), FeatureVal(feature=22, value='m'), FeatureVal(feature=22, value='p'), FeatureVal(feature=22, value='u'), FeatureVal(feature=22, value='w')]\n",
            "first training example: ['e', 'x', 's', 'g', 'f', 'n', 'f', 'w', 'b', 'p', 't', 'e', 'f', 's', 'w', 'w', 'p', 'w', 'o', 'e', 'k', 's', 'g']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw3GLmfUY5Bi"
      },
      "source": [
        "We can see that there are many multi-valued attributes in the dataset. To simplify the implementation and visualization process of decision trees, we want to **convert multi-valued attributes into multiple binary attributes** by checking whether a feature has a specific value (see the example below). In this way, the generated decision trees will be **binary** trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3QK_YO7XBdN",
        "outputId": "10c553d2-ef67-4b73-9844-59c32ef49907"
      },
      "source": [
        "f = sorted(train.features)[0]\n",
        "\n",
        "print(\"Here is an example of how to test whether a feature has a specific value\")\n",
        "print(train.data[100][f.feature] == f.value)\n",
        "print(train.data[0][f.feature] == f.value)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is an example of how to test whether a feature has a specific value\n",
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNeRwBNRb6Zn"
      },
      "source": [
        "# ID3 algorithm (15 points)\n",
        "\n",
        "First, try running the provided starter code in the cell below.\n",
        "\n",
        "The provided code simply “learns” a decision tree consisting of a root node with no children that always predicts “Yes”. The program prints out this tree (consisting of a single node with no children), and then prints its evaluated accuracy on the test set which should be around 0.5.\n",
        "\n",
        "Your job is to implement the functions InformationGain() and ID3() to grow a decision tree from the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnaO01VfXh1V",
        "outputId": "2005b993-58bb-4525-f566-96ed0f2d7bed"
      },
      "source": [
        "DtNode = namedtuple(\"DtNode\", \"fVal, nPosNeg, gain, left, right\")\n",
        "\n",
        "POS_CLASS = 'e'\n",
        "NEG_CLASS = 'p'\n",
        "ALPHA = 1 # laplace smoothing\n",
        "\n",
        "def InformationGain(data, f):\n",
        "    #TODO: Calculate the information gain given a attribute/feature. (5 points).\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        data:\n",
        "            Input examples.\n",
        "        f:\n",
        "            A selected feature.\n",
        "\n",
        "    Returns:\n",
        "        :A (info. gain value, #pos examples, #neg examples) tuple\n",
        "    \"\"\"\n",
        "    info_gain, npos, nneg = 0, 0, 0\n",
        "    return (info_gain, npos, nneg)\n",
        "\n",
        "def Classify(tree, instance):\n",
        "    if tree.left == None and tree.right == None:\n",
        "        return tree.nPosNeg[0] > tree.nPosNeg[1]\n",
        "    elif instance[tree.fVal.feature] == tree.fVal.value:\n",
        "        return Classify(tree.left, instance)\n",
        "    else:\n",
        "        return Classify(tree.right, instance)\n",
        "\n",
        "def Accuracy(tree, data):\n",
        "    nCorrect = 0\n",
        "    for d in data:\n",
        "        if Classify(tree, d) == (d[0] == POS_CLASS):\n",
        "            nCorrect += 1\n",
        "    \n",
        "    print(f\"The accuracy is: {float(nCorrect) / len(data)}\")\n",
        "\n",
        "def PrintTree(node, prefix=''):\n",
        "    if prefix == '':\n",
        "        print('root:')\n",
        "    print(\"%s>next_split=%s\\t edible/poisonous=%s\\t info_gain=%s\" % (prefix, node.fVal, node.nPosNeg, node.gain))\n",
        "    if node.left != None:\n",
        "        print(f\"{prefix}{node.fVal}==True:\")\n",
        "        PrintTree(node.left, prefix + '-')\n",
        "    if node.right != None:\n",
        "        print(f\"{prefix}{node.fVal}==False:\")\n",
        "        PrintTree(node.right, prefix + '-')    \n",
        "    print()    \n",
        "\n",
        "def SavePredictions(tree, data, outFile):\n",
        "    fOut = open(outFile, 'w')\n",
        "    for d in data:\n",
        "        if Classify(tree, d):\n",
        "            fOut.write(f\"{POS_CLASS}\\n\")\n",
        "        else:\n",
        "            fOut.write(f\"{NEG_CLASS}\\n\")\n",
        "        \n",
        "def ID3(data, features, MIN_GAIN=0.1):\n",
        "    #TODO: Implement ID3 algorithm which outputs **binary** decision trees (10 points).\n",
        "    #Hint: Make sure you use the converted binary features following the example above.\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        data:\n",
        "            Input examples.\n",
        "        features:\n",
        "            Input features sets.\n",
        "        MIN_GAIN:\n",
        "            A threhold for informaiton gain to make further splits.\n",
        "\n",
        "    Returns:\n",
        "        :A built decision tree (using DtNode defined above)\n",
        "    \"\"\"\n",
        "    return DtNode(None, (0, 0), 0, None, None)\n",
        "\n",
        "train = MushroomData('train.data')\n",
        "dev = MushroomData('dev.data')\n",
        "test = MushroomData('test.data')\n",
        "\n",
        "dTree = ID3(train.data, train.features, MIN_GAIN=0.01)\n",
        "    \n",
        "PrintTree(dTree)\n",
        "\n",
        "Accuracy(dTree, dev.data)\n",
        "\n",
        "SavePredictions(dTree, test.data, 'test_pred.txt')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root:\n",
            ">next_split=None\t edible/poisonous=(0, 0)\t info_gain=0\n",
            "\n",
            "The accuracy is: 0.458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OQxQmc5gz08"
      },
      "source": [
        "## Gradescope\n",
        "\n",
        "Gradescope allows you to add multiple files to your submission. Please submit this notebook along with the test set prediction:\n",
        "* Project_1_Release.ipynb\n",
        "* test_pred.txt\n",
        "\n",
        "To download this notebook, go to `File > Download.ipynb`. You can download the predictions from Colab by clicking the folder icon on the left and finding them under Files. \n",
        "\n",
        "Please make sure that you name the files as specified above. You will be able to see the test set accuracy for your predictions. However, the final score will be assigned later based on accuracy and implementation. \n",
        "\n",
        "When submitting the .ipynb notebook, please make sure that all the cells run when executed in order starting from a fresh session. If the code doesn't take too long to run, you can re-run everything with `Runtime -> Restart and run all`\n",
        "\n",
        "You can submit multiple times before the deadline and choose the submission which you want to be graded by going to `Submission History` on gradescope.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXKQ7FL7g5JR"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}